# 第一章 绪论
1.	了解机器学习的目的：让机器能像人一样具有学习能力
2.	了解机器学习领域奠基人之一、美国工程院院士：Tom Mitchell教授
3.	了解机器学习的当前定义：利用经验改善计算机系统自身的性能
-	经验对应历史数据，如：互联网数据、科学实验数据等
-	计算机系统对应机器学习模型，如：决策树、支持向量机等
-	性能则是模型对新数据的处理能力，如：分类和预测性能等
4.	了解人工智能的三个学派：符号主义，链接主义，行为主义
5.	了解人工智能的三个时期：推理期，知识期，学习期
6.	熟悉机器学习的三类学习方法：无监督学习，监督学习，强化学习
7.	熟悉人工智能三个学派和机器学习三个时期的特点和关联
8.	熟悉机器学习三类学习方法的区别和联系
-	监督学习（Supervised Learning）：有标注信息的学习过程
-	无监督学习（ Unsupervised Learning ）：无标注信息的学习过程
-	强化学习（Reinforcement Learning）：以试错为主的学习过程
9.	了解1）样本和数据集；2）特征和特征向量的基本概念
10.	了解假设和真值的基本概念：
-	假设（Hypothesis）：数据中潜在的某种规律，如：天气数据中潜在的季节周期性
-	真值（Ground-truth）：潜在规律的自身称之为“真实”或“真相”，在训练集中常被用作标注信息
11.	了解1）训练集和测试集；2）分类和回归的基本概念
-	分类（Classification）：预测值为离散值，如：好瓜，坏瓜
-	回归（Regression）：预测值为连续值，如：瓜的成熟度0.95、0.37等
12.	熟悉归纳和演绎的基本概念
-	归纳（Induction）：从特殊到一般的“泛化”（Generalization）过程，即：从具体的事实归结出一般性规律
-	演绎（Deduction）：从一般到特殊的“特化”（Specialization）过程，即：从基础原理推演出具体状况
13.	了解奥卡姆剃刀的核心思想：若有多个假设与观察一致，则选最简单的那个

# 第 2 章 模型评估与选择
1. 掌握经验误差、泛化误差概念， 理解过拟合、欠拟合概念。
2. 掌握模型评估方法，理解各类评估方法的概念， 了解不同评估方法的利弊。
3. 了解机器学习中常涉及的两类参数(超参数、 模型参数)
4. 掌握回归任务最常用的性能度量公式(MSE)，了解简单分类任务的性能度量公式。
5. 掌握并理解查准率、查全率与 F1 公式及相关概念, 并能熟练掌握相关计算。
6. 掌握简单分类结果的“混淆矩阵”，理解四种分类情况(TP、 FP、 TN、 FN)， 理解 P-R 曲线代表的含义。
7. 理解 ROC、 AUC 曲线的含义及相关概念。
8. 了解代价敏感错误率与代价曲线。

# 第三章 线性模型
1.	了解一元线性回归和多元线性回归的区别和联系
2.	撑握线性模型的基本形式和最小二乘目标函数的基本形式
3.	撑握线性模型参数求解方法和闭式解的求解方法
4.	熟悉L1正则和L2正则的区别和联系（给出图解）
5.	熟悉梯度下降算法的迭代过程
6.	熟悉线性回归的优点和不足
7.	了解Sigmoid函数基本形式
8.	了解阶跃函数的优点和不足
9.	了解凸函数和非凸函数的定义
10.	了解线性判别分析的基本思想
-	同类样例的投影尽可能接近、异类样例的投影点尽可能远离
11.	了解线性分析同类样例投影尽可能接近和异类样例尽可能远离的计算方法
12.	了解多分类学习问题的基本思想
-	拆解法：将一个多分类任务拆分为若干个二分类任务求解
13.	了解类别不平衡问题的定义：分类任务中不同类别的训练样例数目差别很大的情况

# 第 4 章 决策树
1. 掌握并理解决策树生成的基本流程
2. 掌握并理解信息熵、信息增益、增益率、基尼指数，并能熟练进行相关计算
3. 掌握剪枝的目的以及常用的剪枝方式的基本过程
4. 了解决策树中连续与缺失值数据的处理
5. 了解多变量决策树以及决策树的优缺点

# 第 5 章 神经网络
1. 熟悉感知机解决线性可分问题的原理与步骤。
2. 理解图 5.5 中的两层感知机为何可以解决异或问题。
3. 重点掌握 5.3 小节误差逆传播算法。包括计算、原理、工作流程。
4. 理解梯度下降策略步长大小对于模型训练的影响。
5. 掌握神经网络算法“跳出”局部极小的方法。
6. 熟悉神经网络过拟合的定义以及常用的解决方法。
7. 了解标准 BP 算法与累积 BP 算法的区别。
8. 理解 CNN 网络如何通过权共享节省训练开销。

# 第六章 支持向量机

1.	了解 1）样本点到超平面的距离公式；2）为什么要计算两者之间的距离
2.	了解支持向量机“间隔”的定义和计算公式
3.	了解支持向量机的“间隔最大化”和等价“间隔最小化”的定义和公式
4.	熟悉支持向量机一般形式公式、拉格朗日函数公式和对偶函数公式
5.	掌握拉格朗日函数的偏导数求解过程
6.	掌握从拉格朗日函数到对偶函数的求解过程
7.	熟悉支持向量机为什么要引入拉格朗日乘子？为什么要求对偶函数？
8.	了解五类基本核函数
9.	熟悉SMO算法的基本思想和变量选择的基本步骤
-	基本思想：先固定αi之外的所有参数，然后求αi上的极值。由于存在(6.10)式的约束，若固定αi之外的其它变量，则αi可由其他变量导出。于是，SMO每次选择两个变量αi和αj，并固定其他参数
-	步骤1：选取一对需要更新的变量αi和αj
-	步骤2：固定αi和αj以外的参数，求解(6.11)式获得更新后的αi和αj 
10.	了解软间隔和硬间隔定义，以及各自的优点和不足
-	硬间隔：要求所有样本均满足约束（6.3），即：全部划分正确
-	软间隔：允许支持向量机在一些样本上出错，即：允许部分划分错误
11.	了解三种常见的替代损失函数，即：Hinge损失、指数损失（exponential loss）、对率损失（logistic loss），以及三种损失函数的曲线形式
12.	熟悉Hinge损失、指数损失（exponential loss）、对率损失（logistic loss）的区别和联系
13.	了解软间隔支持向量机中松弛变量的作用
14.	了解支持向量回归解决的主要问题

# 第7章 贝叶斯分类器
-	了解贝叶斯决策论基本原理
-	了解总体决策风险、贝叶斯判定准则和贝叶斯最优分类器
-	重点掌握贝叶斯定理（先验 似然 后验 的定义及三者之间的关系）
-	重点掌握生成式模型、判别式模型（定义，区别，代表性方法）
-	重点掌握参数估计的两种学派（观点，区别，代表性方法）
-	重点掌握极大似然估计方法的推导过程及特点
-	重点掌握朴素贝叶斯分类器原理、应用、优缺点
-	重点掌握EM算法核心思想、混合高斯分布及其参数推导

# 第9章 聚类
-	了解聚类任务
-	重点掌握性能度量和距离计算
-	原型聚类中，重点掌握K均值聚类算法，了解学习向量量化算法，重点掌握高斯混合聚类算法
-	重点掌握密度聚类算法
-	重点掌握层次聚类，特别是聚类簇距离分别由最小距离和最大距离计算

# 第10章 降维与度量学习
-	重点掌握K近邻学习
-	重点掌握低维嵌入的多维缩放算法
-	重点掌握主成分分析算法
-	了解核化线性降维
-	重点掌握流型学习算法
-	了解度量学习

# 第11章 特征选择与稀疏学习
-	了解特征子集搜索，重点掌握特征子集评价，特别是应用到过滤式特征选择
-	重点掌握特征选择算法分类
-	掌握过滤式算法、包裹式算法，重点掌握嵌入式特征选择方法以及L1正则化特性及推导
-	掌握稀疏表示与字典学习

# 第13章 半监督学习
-	了解未标记样本，掌握半监督学习的常见假设，掌握半监督学习的分类
-	重点掌握生成式方法
-	重点掌握半监督SVM算法
-	重点掌握图半监督学习算法
-	掌握半监督聚类算法

# 第14章  概率图模型
-	了解概率图模型，了解常用近似推断方法及其特点
-	重点掌握变分推断（问题，解题思路，均场假设，目标函数）

